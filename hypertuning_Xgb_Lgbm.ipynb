{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning using Oputa on XGB model and LGBM and Catboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train = pd.read_csv(\"C:/Users/Asus/Documents/MMAI/869_MachineLearningAI/Team_assignment/train/agg_train.csv\",low_memory=False)\n",
    "agg_test = pd.read_csv(\"C:/Users/Asus/Documents/MMAI/869_MachineLearningAI/Team_assignment/test/agg_test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>consumption_diff_sum</th>\n",
       "      <th>consumption_diff_mean</th>\n",
       "      <th>tarif_type_count</th>\n",
       "      <th>reading_remarque_mean</th>\n",
       "      <th>counter_statue_count</th>\n",
       "      <th>counter_coefficient_mean</th>\n",
       "      <th>consommation_level_1_mean</th>\n",
       "      <th>consommation_level_2_mean</th>\n",
       "      <th>consommation_level_3_mean</th>\n",
       "      <th>consommation_level_4_mean</th>\n",
       "      <th>counter_number_nunique</th>\n",
       "      <th>months_number_mean</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>invoice_freq</th>\n",
       "      <th>daily_consumption</th>\n",
       "      <th>client_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>6.971429</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>352.400000</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.628571</td>\n",
       "      <td>4901</td>\n",
       "      <td>140.028571</td>\n",
       "      <td>2.592124</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>7.216216</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>557.540541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.324324</td>\n",
       "      <td>4913</td>\n",
       "      <td>132.783784</td>\n",
       "      <td>4.198860</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7.055556</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>798.611111</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.444444</td>\n",
       "      <td>4921</td>\n",
       "      <td>273.388889</td>\n",
       "      <td>3.059744</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>2664</td>\n",
       "      <td>133.200000</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>663.714286</td>\n",
       "      <td>104.857143</td>\n",
       "      <td>117.357143</td>\n",
       "      <td>36.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>1585</td>\n",
       "      <td>113.214286</td>\n",
       "      <td>7.825237</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  disrict  client_catg  region  consumption_diff_sum  \\\n",
       "0           0       60           11     101                     0   \n",
       "1           1       69           11     107                     0   \n",
       "2           2       62           11     301                     0   \n",
       "3           3       69           11     105                     0   \n",
       "4           4       62           11     303                     0   \n",
       "\n",
       "   consumption_diff_mean  tarif_type_count  reading_remarque_mean  \\\n",
       "0                    0.0                35               6.971429   \n",
       "1                    0.0                37               7.216216   \n",
       "2                    0.0                18               7.055556   \n",
       "3                    0.0                20               6.150000   \n",
       "4                    0.0                14               8.857143   \n",
       "\n",
       "   counter_statue_count  counter_coefficient_mean  consommation_level_1_mean  \\\n",
       "0                    35                       1.0                 352.400000   \n",
       "1                    37                       1.0                 557.540541   \n",
       "2                    18                       1.0                 798.611111   \n",
       "3                    20                       1.0                   1.200000   \n",
       "4                    14                       1.0                 663.714286   \n",
       "\n",
       "   consommation_level_2_mean  consommation_level_3_mean  \\\n",
       "0                  10.571429                   0.000000   \n",
       "1                   0.000000                   0.000000   \n",
       "2                  37.888889                   0.000000   \n",
       "3                   0.000000                   0.000000   \n",
       "4                 104.857143                 117.357143   \n",
       "\n",
       "   consommation_level_4_mean  counter_number_nunique  months_number_mean  \\\n",
       "0                   0.000000                       1            4.628571   \n",
       "1                   0.000000                       1            4.324324   \n",
       "2                   0.000000                       1            6.444444   \n",
       "3                   0.000000                       1            4.200000   \n",
       "4                  36.714286                       1            3.714286   \n",
       "\n",
       "   tenure_days  invoice_freq  daily_consumption  client_period  \n",
       "0         4901    140.028571           2.592124             25  \n",
       "1         4913    132.783784           4.198860             17  \n",
       "2         4921    273.388889           3.059744             33  \n",
       "3         2664    133.200000           0.009009             16  \n",
       "4         1585    113.214286           7.825237              5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>consumption_diff_sum</th>\n",
       "      <th>consumption_diff_mean</th>\n",
       "      <th>tarif_type_count</th>\n",
       "      <th>reading_remarque_mean</th>\n",
       "      <th>counter_statue_count</th>\n",
       "      <th>counter_coefficient_mean</th>\n",
       "      <th>consommation_level_1_mean</th>\n",
       "      <th>consommation_level_2_mean</th>\n",
       "      <th>consommation_level_3_mean</th>\n",
       "      <th>consommation_level_4_mean</th>\n",
       "      <th>counter_number_nunique</th>\n",
       "      <th>months_number_mean</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>invoice_freq</th>\n",
       "      <th>daily_consumption</th>\n",
       "      <th>client_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>6.810811</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.135135</td>\n",
       "      <td>3.243243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.378378</td>\n",
       "      <td>4967</td>\n",
       "      <td>134.243243</td>\n",
       "      <td>3.660358</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>7.636364</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1091.409091</td>\n",
       "      <td>843.136364</td>\n",
       "      <td>182.318182</td>\n",
       "      <td>586.318182</td>\n",
       "      <td>1</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>3744</td>\n",
       "      <td>170.181818</td>\n",
       "      <td>12.438835</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74</td>\n",
       "      <td>7.459459</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>554.040541</td>\n",
       "      <td>37.364865</td>\n",
       "      <td>15.743243</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5022</td>\n",
       "      <td>67.864865</td>\n",
       "      <td>8.946436</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>6.575000</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2486</td>\n",
       "      <td>62.150000</td>\n",
       "      <td>3.931617</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>301</td>\n",
       "      <td>-116</td>\n",
       "      <td>-2.188679</td>\n",
       "      <td>53</td>\n",
       "      <td>7.905660</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>568.188679</td>\n",
       "      <td>145.056604</td>\n",
       "      <td>33.679245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.528302</td>\n",
       "      <td>5137</td>\n",
       "      <td>96.924528</td>\n",
       "      <td>7.706249</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  disrict  client_catg  region  consumption_diff_sum  \\\n",
       "0           0       62           11     307                     0   \n",
       "1           1       69           11     103                     0   \n",
       "2           2       62           11     310                     0   \n",
       "3           3       60           11     101                     0   \n",
       "4           4       62           11     301                  -116   \n",
       "\n",
       "   consumption_diff_mean  tarif_type_count  reading_remarque_mean  \\\n",
       "0               0.000000                37               6.810811   \n",
       "1               0.000000                22               7.636364   \n",
       "2               0.000000                74               7.459459   \n",
       "3               0.000000                40               6.575000   \n",
       "4              -2.188679                53               7.905660   \n",
       "\n",
       "   counter_statue_count  counter_coefficient_mean  consommation_level_1_mean  \\\n",
       "0                    37                       1.0                 488.135135   \n",
       "1                    22                       1.0                1091.409091   \n",
       "2                    74                       1.0                 554.040541   \n",
       "3                    40                       1.0                 244.350000   \n",
       "4                    53                       1.0                 568.188679   \n",
       "\n",
       "   consommation_level_2_mean  consommation_level_3_mean  \\\n",
       "0                   3.243243                   0.000000   \n",
       "1                 843.136364                 182.318182   \n",
       "2                  37.364865                  15.743243   \n",
       "3                   0.000000                   0.000000   \n",
       "4                 145.056604                  33.679245   \n",
       "\n",
       "   consommation_level_4_mean  counter_number_nunique  months_number_mean  \\\n",
       "0                   0.000000                       1            4.378378   \n",
       "1                 586.318182                       1            4.545455   \n",
       "2                   0.162162                       2            4.000000   \n",
       "3                   0.000000                       2            3.900000   \n",
       "4                   0.000000                       3            4.528302   \n",
       "\n",
       "   tenure_days  invoice_freq  daily_consumption  client_period  \n",
       "0         4967    134.243243           3.660358             17  \n",
       "1         3744    170.181818          12.438835             10  \n",
       "2         5022     67.864865           8.946436             15  \n",
       "3         2486     62.150000           3.931617             20  \n",
       "4         5137     96.924528           7.706249             42  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train =pd.read_csv(\"C:/Users/Asus/Documents/MMAI/869_MachineLearningAI/Team_assignment/train/client_train.csv\",low_memory=False)\n",
    "target = client_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_transformer(Y):\n",
    "    return make_pipeline(\n",
    "        FunctionTransformer(rbf_kernel, kw_args=dict(Y=Y, gamma=0.1),feature_names_out=\"one-to-one\"),\n",
    "        StandardScaler()\n",
    "    )\n",
    "# def num_transformer():\n",
    "#     return make_pipeline(\n",
    "#             FunctionTransformer(lambda x: x.astype(int), validate=False)\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    " ('onehot', OneHotEncoder(handle_unknown=\"ignore\"), ['disrict']),\n",
    " (\"rbf_transformer_105\", rbf_transformer([[105]]), [\"region\"]),\n",
    " (\"rbf_transformer_305\", rbf_transformer([[305]]), [\"region\"]),\n",
    " (\"rbf_transformer_375\", rbf_transformer([[375]]), [\"region\"]),\n",
    " ], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"C:/Users/Asus/Documents/MMAI/869_MachineLearningAI/Team_assignment/train/train_df.csv\",low_memory=False)\n",
    "test_df = pd.read_csv(\"C:/Users/Asus/Documents/MMAI/869_MachineLearningAI/Team_assignment/test/test_df.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135488, 388)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_group</th>\n",
       "      <th>creation_day</th>\n",
       "      <th>creation_month</th>\n",
       "      <th>creation_year</th>\n",
       "      <th>duration</th>\n",
       "      <th>target</th>\n",
       "      <th>disrict_60</th>\n",
       "      <th>disrict_62</th>\n",
       "      <th>disrict_63</th>\n",
       "      <th>disrict_69</th>\n",
       "      <th>...</th>\n",
       "      <th>Rem_9_GAZ</th>\n",
       "      <th>consumption_diff_sum</th>\n",
       "      <th>consumption_diff_mean</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>invoice_freq</th>\n",
       "      <th>daily_consumption</th>\n",
       "      <th>first_invoice_gap_ELEC</th>\n",
       "      <th>last_invoice_gap_ELEC</th>\n",
       "      <th>first_invoice_gap_GAZ</th>\n",
       "      <th>last_invoice_gap_GAZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>1994</td>\n",
       "      <td>324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2888.0</td>\n",
       "      <td>82.51428</td>\n",
       "      <td>4901</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>8844.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>129.43243</td>\n",
       "      <td>4913</td>\n",
       "      <td>132.8</td>\n",
       "      <td>0.974600</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1986</td>\n",
       "      <td>429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2286.0</td>\n",
       "      <td>127.00000</td>\n",
       "      <td>4921</td>\n",
       "      <td>273.5</td>\n",
       "      <td>0.464600</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>12103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1996</td>\n",
       "      <td>305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>2664</td>\n",
       "      <td>133.2</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>3256.0</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>237.92857</td>\n",
       "      <td>1585</td>\n",
       "      <td>113.2</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region_group  creation_day  creation_month  creation_year  duration  \\\n",
       "0             2            31              12           1994       324   \n",
       "1             2            29               5           2002       235   \n",
       "2             3            13               3           1986       429   \n",
       "3             2            11               7           1996       305   \n",
       "4             3            14              10           2014        86   \n",
       "\n",
       "   target  disrict_60  disrict_62  disrict_63  disrict_69  ...  Rem_9_GAZ  \\\n",
       "0     0.0         1.0         0.0         0.0         0.0  ...        0.0   \n",
       "1     0.0         0.0         0.0         0.0         1.0  ...        0.0   \n",
       "2     0.0         0.0         1.0         0.0         0.0  ...        0.0   \n",
       "3     0.0         0.0         0.0         0.0         1.0  ...        0.0   \n",
       "4     0.0         0.0         1.0         0.0         0.0  ...        0.0   \n",
       "\n",
       "   consumption_diff_sum  consumption_diff_mean  tenure_days  invoice_freq  \\\n",
       "0                2888.0               82.51428         4901         140.0   \n",
       "1                4789.0              129.43243         4913         132.8   \n",
       "2                2286.0              127.00000         4921         273.5   \n",
       "3                   6.0                0.30000         2664         133.2   \n",
       "4                3331.0              237.92857         1585         113.2   \n",
       "\n",
       "   daily_consumption  first_invoice_gap_ELEC  last_invoice_gap_ELEC  \\\n",
       "0           0.589400                  3943.0                 8844.0   \n",
       "1           0.974600                  1239.0                 6152.0   \n",
       "2           0.464600                  7182.0                12103.0   \n",
       "3           0.002253                  3256.0                 5920.0   \n",
       "4           2.020000                   122.0                 1707.0   \n",
       "\n",
       "   first_invoice_gap_GAZ  last_invoice_gap_GAZ  \n",
       "0                    0.0                   0.0  \n",
       "1                    0.0                   0.0  \n",
       "2                    0.0                   0.0  \n",
       "3                    0.0                   0.0  \n",
       "4                    0.0                   0.0  \n",
       "\n",
       "[5 rows x 388 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def objective(trial,X,y):\n",
    " # 'is_unbalance':True,\n",
    "    lgbm_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt', \n",
    "        'metric': 'auc',\n",
    "        \"n_estimators\": 1000,\n",
    "        'scale_pos_weight': trial.suggest_int('scale_pos_weight', 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"num_iterations\": 500,\n",
    "        \"num_leaves\": trial.suggest_int('num_leaves',20,100),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\",20,500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\",5,20),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\",0.5,1.0),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\",0.5,1.0)\n",
    "    }\n",
    "    \n",
    "    light_GBM =ImPipeline([\n",
    "    ('model', LGBMClassifier(**lgbm_params))\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    light_GBM.fit(train_df, target)\n",
    "    cv_scores = cross_val_score(light_GBM, X, y, cv=10, n_jobs=-1, scoring=\"roc_auc\")\n",
    "    score = np.mean(cv_scores)\n",
    "    # scorestd = cv_scores.std()\n",
    "    return score  # Replace with appropriate metric\n",
    "\n",
    "# Create a study object and specify the direction is 'maximize'.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Start the optimization\n",
    "study.optimize(lambda trial: objective(trial, train_df, target), n_trials=100,  gc_after_trial=True)\n",
    "\n",
    "# Print the optimal parameters\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n10 mins\\nBest is trial 7 with value: 0.8369938153532145.\\n{'scale_pos_weight': 5, 'learning_rate': 0.007708305735559817}\\n100 trial 72 mins\\nBest is trial 88 with value: 0.839493765558394.\\n{'scale_pos_weight': 3, 'learning_rate': 0.023458592474959277, 'num_leaves': 43, 'min_child_samples': 123, \\n'max_depth': 16, 'subsample': 0.9637220440391915, 'feature_fraction': 0.566261327139611}\\n\\n20 hrs\\nBest is trial 51 with value: 0.9026014242790721.\\n[LightGBM] [Warning] feature_fraction is set=0.6132055000901042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6132055000901042\\n[LightGBM] [Warning] feature_fraction is set=0.6132055000901042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6132055000901042\\n[LightGBM] [Info] Number of positive: 7566, number of negative: 127922\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params\n",
    "\n",
    "'''\n",
    "10 mins\n",
    "Best is trial 7 with value: 0.8369938153532145.\n",
    "{'scale_pos_weight': 5, 'learning_rate': 0.007708305735559817}\n",
    "\n",
    "100 trial 72 mins\n",
    "Best is trial 88 with value: 0.839493765558394.\n",
    "{'scale_pos_weight': 3, 'learning_rate': 0.023458592474959277, 'num_leaves': 43, 'min_child_samples': 123, \n",
    "'max_depth': 16, 'subsample': 0.9637220440391915, 'feature_fraction': 0.566261327139611}\n",
    "\n",
    "20 hrs\n",
    "Best is trial 51 with value: 0.9026014242790721.\n",
    "Trial 51 finished with value: 0.9026014242790721 and parameters: {'scale_pos_weight': 3, 'learning_rate': 0.017044136762318283,\n",
    "'num_leaves': 79, 'min_child_samples': 98, 'max_depth': 11, 'subsample': 0.8679507197110152, 'feature_fraction': 0.5453545038655571}.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5453545038655571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5453545038655571\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5453545038655571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5453545038655571\n",
      "[LightGBM] [Info] Number of positive: 7566, number of negative: 127922\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 56368\n",
      "[LightGBM] [Info] Number of data points in the train set: 135488, number of used features: 310\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055843 -> initscore=-2.827756\n",
      "[LightGBM] [Info] Start training from score -2.827756\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 LGBMClassifier(feature_fraction=0.5453545038655571,\n",
       "                                learning_rate=0.017044136762318283,\n",
       "                                max_depth=11, metric=&#x27;auc&#x27;,\n",
       "                                min_child_samples=98, n_estimators=1000,\n",
       "                                num_iterations=500, num_leaves=79,\n",
       "                                objective=&#x27;binary&#x27;, scale_pos_weight=3,\n",
       "                                subsample=0.8679507197110152))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 LGBMClassifier(feature_fraction=0.5453545038655571,\n",
       "                                learning_rate=0.017044136762318283,\n",
       "                                max_depth=11, metric=&#x27;auc&#x27;,\n",
       "                                min_child_samples=98, n_estimators=1000,\n",
       "                                num_iterations=500, num_leaves=79,\n",
       "                                objective=&#x27;binary&#x27;, scale_pos_weight=3,\n",
       "                                subsample=0.8679507197110152))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(feature_fraction=0.5453545038655571,\n",
       "               learning_rate=0.017044136762318283, max_depth=11, metric=&#x27;auc&#x27;,\n",
       "               min_child_samples=98, n_estimators=1000, num_iterations=500,\n",
       "               num_leaves=79, objective=&#x27;binary&#x27;, scale_pos_weight=3,\n",
       "               subsample=0.8679507197110152)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('model',\n",
       "                 LGBMClassifier(feature_fraction=0.5453545038655571,\n",
       "                                learning_rate=0.017044136762318283,\n",
       "                                max_depth=11, metric='auc',\n",
       "                                min_child_samples=98, n_estimators=1000,\n",
       "                                num_iterations=500, num_leaves=79,\n",
       "                                objective='binary', scale_pos_weight=3,\n",
       "                                subsample=0.8679507197110152))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt', \n",
    "        'metric': 'auc',\n",
    "        \"n_estimators\": 1000,\n",
    "        'scale_pos_weight': 3,\n",
    "        \"learning_rate\": 0.017044136762318283,\n",
    "        \"num_iterations\": 500,\n",
    "        \"num_leaves\": 79,\n",
    "        \"min_child_samples\": 98,\n",
    "        \"max_depth\": 11,\n",
    "        \"subsample\": 0.8679507197110152,\n",
    "        \"feature_fraction\": 0.5453545038655571\n",
    "    }\n",
    "    \n",
    "light_GBM =ImPipeline([\n",
    "('model', LGBMClassifier(**params))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "light_GBM.fit(train_df, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tuning XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['target']\n",
    "train_df.drop(columns=['target'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_group</th>\n",
       "      <th>creation_day</th>\n",
       "      <th>creation_month</th>\n",
       "      <th>creation_year</th>\n",
       "      <th>duration</th>\n",
       "      <th>disrict_60</th>\n",
       "      <th>disrict_62</th>\n",
       "      <th>disrict_63</th>\n",
       "      <th>disrict_69</th>\n",
       "      <th>client_catg_11</th>\n",
       "      <th>...</th>\n",
       "      <th>Rem_9_GAZ</th>\n",
       "      <th>consumption_diff_sum</th>\n",
       "      <th>consumption_diff_mean</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>invoice_freq</th>\n",
       "      <th>daily_consumption</th>\n",
       "      <th>first_invoice_gap_ELEC</th>\n",
       "      <th>last_invoice_gap_ELEC</th>\n",
       "      <th>first_invoice_gap_GAZ</th>\n",
       "      <th>last_invoice_gap_GAZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>1994</td>\n",
       "      <td>324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2888.0</td>\n",
       "      <td>82.51428</td>\n",
       "      <td>4901</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>8844.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>129.43243</td>\n",
       "      <td>4913</td>\n",
       "      <td>132.8</td>\n",
       "      <td>0.974600</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1986</td>\n",
       "      <td>429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2286.0</td>\n",
       "      <td>127.00000</td>\n",
       "      <td>4921</td>\n",
       "      <td>273.5</td>\n",
       "      <td>0.464600</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>12103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1996</td>\n",
       "      <td>305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>2664</td>\n",
       "      <td>133.2</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>3256.0</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>237.92857</td>\n",
       "      <td>1585</td>\n",
       "      <td>113.2</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region_group  creation_day  creation_month  creation_year  duration  \\\n",
       "0             2            31              12           1994       324   \n",
       "1             2            29               5           2002       235   \n",
       "2             3            13               3           1986       429   \n",
       "3             2            11               7           1996       305   \n",
       "4             3            14              10           2014        86   \n",
       "\n",
       "   disrict_60  disrict_62  disrict_63  disrict_69  client_catg_11  ...  \\\n",
       "0         1.0         0.0         0.0         0.0             1.0  ...   \n",
       "1         0.0         0.0         0.0         1.0             1.0  ...   \n",
       "2         0.0         1.0         0.0         0.0             1.0  ...   \n",
       "3         0.0         0.0         0.0         1.0             1.0  ...   \n",
       "4         0.0         1.0         0.0         0.0             1.0  ...   \n",
       "\n",
       "   Rem_9_GAZ  consumption_diff_sum  consumption_diff_mean  tenure_days  \\\n",
       "0        0.0                2888.0               82.51428         4901   \n",
       "1        0.0                4789.0              129.43243         4913   \n",
       "2        0.0                2286.0              127.00000         4921   \n",
       "3        0.0                   6.0                0.30000         2664   \n",
       "4        0.0                3331.0              237.92857         1585   \n",
       "\n",
       "   invoice_freq  daily_consumption  first_invoice_gap_ELEC  \\\n",
       "0         140.0           0.589400                  3943.0   \n",
       "1         132.8           0.974600                  1239.0   \n",
       "2         273.5           0.464600                  7182.0   \n",
       "3         133.2           0.002253                  3256.0   \n",
       "4         113.2           2.020000                   122.0   \n",
       "\n",
       "   last_invoice_gap_ELEC  first_invoice_gap_GAZ  last_invoice_gap_GAZ  \n",
       "0                 8844.0                    0.0                   0.0  \n",
       "1                 6152.0                    0.0                   0.0  \n",
       "2                12103.0                    0.0                   0.0  \n",
       "3                 5920.0                    0.0                   0.0  \n",
       "4                 1707.0                    0.0                   0.0  \n",
       "\n",
       "[5 rows x 387 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         region_group  creation_day  creation_month  creation_year  duration  \\\n",
       "0                  2            31              12           1994       324   \n",
       "1                  2            29               5           2002       235   \n",
       "2                  3            13               3           1986       429   \n",
       "3                  2            11               7           1996       305   \n",
       "4                  3            14              10           2014        86   \n",
       "...              ...           ...             ...            ...       ...   \n",
       "135483             3            26               7           2004       209   \n",
       "135484             3            25              10           2012       110   \n",
       "135485             3            22              11           2011       121   \n",
       "135486             2            22              12           1993       336   \n",
       "135487             2            18               2           1986       430   \n",
       "\n",
       "        disrict_60  disrict_62  disrict_63  disrict_69  client_catg_11  ...  \\\n",
       "0              1.0         0.0         0.0         0.0             1.0  ...   \n",
       "1              0.0         0.0         0.0         1.0             1.0  ...   \n",
       "2              0.0         1.0         0.0         0.0             1.0  ...   \n",
       "3              0.0         0.0         0.0         1.0             1.0  ...   \n",
       "4              0.0         1.0         0.0         0.0             1.0  ...   \n",
       "...            ...         ...         ...         ...             ...  ...   \n",
       "135483         0.0         1.0         0.0         0.0             1.0  ...   \n",
       "135484         0.0         0.0         1.0         0.0             1.0  ...   \n",
       "135485         0.0         0.0         1.0         0.0             1.0  ...   \n",
       "135486         1.0         0.0         0.0         0.0             1.0  ...   \n",
       "135487         1.0         0.0         0.0         0.0             1.0  ...   \n",
       "\n",
       "        Rem_9_GAZ  consumption_diff_sum  consumption_diff_mean  tenure_days  \\\n",
       "0          0.0000                2888.0              82.514280         4901   \n",
       "1          0.0000                4789.0             129.432430         4913   \n",
       "2          0.0000                2286.0             127.000000         4921   \n",
       "3          0.0000                   6.0               0.300000         2664   \n",
       "4          0.0000                3331.0             237.928570         1585   \n",
       "...           ...                   ...                    ...          ...   \n",
       "135483     0.0000                  35.0               0.492958         5099   \n",
       "135484     0.6665                1931.0              47.097560         2307   \n",
       "135485     1.0000                2323.0              64.527780         2821   \n",
       "135486     0.0000                 119.0              59.500000          122   \n",
       "135487     0.0000                 345.0             115.000000          244   \n",
       "\n",
       "        invoice_freq  daily_consumption  first_invoice_gap_ELEC  \\\n",
       "0             140.00           0.589400                  3943.0   \n",
       "1             132.80           0.974600                  1239.0   \n",
       "2             273.50           0.464600                  7182.0   \n",
       "3             133.20           0.002253                  3256.0   \n",
       "4             113.20           2.020000                   122.0   \n",
       "...              ...                ...                     ...   \n",
       "135483         71.80           0.006863                   349.0   \n",
       "135484         56.28           0.837000                   120.0   \n",
       "135485         78.40           0.823000                    85.0   \n",
       "135486         61.00           0.975600                  4258.0   \n",
       "135487         81.30           1.414000                  3628.0   \n",
       "\n",
       "        last_invoice_gap_ELEC  first_invoice_gap_GAZ  last_invoice_gap_GAZ  \n",
       "0                      8844.0                    0.0                   0.0  \n",
       "1                      6152.0                    0.0                   0.0  \n",
       "2                     12103.0                    0.0                   0.0  \n",
       "3                      5920.0                    0.0                   0.0  \n",
       "4                      1707.0                    0.0                   0.0  \n",
       "...                       ...                    ...                   ...  \n",
       "135483                 5448.0                 1310.0                5448.0  \n",
       "135484                 2427.0                  120.0                2427.0  \n",
       "135485                 2906.0                   85.0                1807.0  \n",
       "135486                 4380.0                    0.0                   0.0  \n",
       "135487                 3872.0                    0.0                   0.0  \n",
       "\n",
       "[135488 rows x 387 columns]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "135483    0.0\n",
       "135484    0.0\n",
       "135485    0.0\n",
       "135486    0.0\n",
       "135487    0.0\n",
       "Name: target, Length: 135488, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# numeric_features = [\"\", \"\"]\n",
    "# numeric_transformer = Pipeline(\n",
    "#     steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "# )\n",
    "\n",
    "# categorical_features = [\"\", \"\", \"\"]\n",
    "# categorical_transformer = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "#         (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     ('num', numerical_transformer, make_column_selector(dtype_exclude=object)),\n",
    "#     ('cat', categorical_transformer, make_column_selector(dtype_exclude=object))\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "        \n",
    "def objective(trial,X,y):\n",
    " # 'is_unbalance':True,\n",
    "    params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'booster': 'gbtree',\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 11),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'alpha': trial.suggest_float('alpha', 0, 10),\n",
    "            'lambda': trial.suggest_float('lambda', 0, 10),\n",
    "            'scale_pos_weight': trial.suggest_int('scale_pos_weight', 0, 10),\n",
    "            'n_estimators': 1000\n",
    "            }\n",
    "    \n",
    "    XGBmodel =ImPipeline([\n",
    "    ('model', XGBClassifier(**params))\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    XGBmodel.fit(train_df, target)\n",
    "    cv_scores = cross_val_score(XGBmodel, X, y, cv=10, n_jobs=-1, scoring=\"roc_auc\")\n",
    "    score = np.mean(cv_scores)\n",
    "    # scorestd = cv_scores.std()\n",
    "    return score  # Replace with appropriate metric\n",
    "\n",
    "# Create a study object and specify the direction is 'maximize'.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Start the optimization\n",
    "study.optimize(lambda trial: objective(trial, train_df, target), n_trials=100,  gc_after_trial=True)\n",
    "\n",
    "# Print the optimal parameters\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(study.best_params)\n",
    "# 0.9001688929625951 and parameters: {'learning_rate': 0.02039826866042329, 'max_depth': 5, 'min_child_weight': 4, \n",
    "# 'subsample': 0.6937845559087417, 'gamma': 0.3651378395261624, 'colsample_bytree': 0.6544744376383287, 'alpha': 2.2996772213995964, 'lambda': 2.588895028771817, 'scale_pos_weight': 7}.\n",
    "\n",
    "# Trial 34 finished with value: 0.9031123075164114 and parameters: {'learning_rate': 0.01221636279037111, 'max_depth': 9, 'min_child_weight': 6, \n",
    "# 'subsample': 0.9388323387748934, 'gamma': 0.8647062123246894, \n",
    "# 'colsample_bytree': 0.7644821944288629, 'alpha': 0.8375691885584633, 'lambda': 3.9543889166305703, 'scale_pos_weight': 1}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 34 finished with value: 0.9031123075164114 and parameters: {'learning_rate': 0.01221636279037111, 'max_depth': 9, 'min_child_weight': 6, \n",
    "'subsample': 0.9388323387748934, 'gamma': 0.8647062123246894, \n",
    "'colsample_bytree': 0.7644821944288629, 'alpha': 0.8375691885584633, 'lambda': 3.9543889166305703, 'scale_pos_weight': 1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 XGBClassifier(alpha=0.8375691885584633, base_score=None,\n",
       "                               booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.7644821944288629, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=&#x27;auc&#x27;,\n",
       "                               feature_types=None, gamma=0.8647062123246894,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=3.9543889166305703,\n",
       "                               learning_rate=0.01221636279037111, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=9,\n",
       "                               max_leaves=None, min_child_weight=6, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=1000, n_jobs=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 XGBClassifier(alpha=0.8375691885584633, base_score=None,\n",
       "                               booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.7644821944288629, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=&#x27;auc&#x27;,\n",
       "                               feature_types=None, gamma=0.8647062123246894,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=3.9543889166305703,\n",
       "                               learning_rate=0.01221636279037111, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=9,\n",
       "                               max_leaves=None, min_child_weight=6, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=1000, n_jobs=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.8375691885584633, base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7644821944288629, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0.8647062123246894,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, lambda=3.9543889166305703,\n",
       "              learning_rate=0.01221636279037111, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('model',\n",
       "                 XGBClassifier(alpha=0.8375691885584633, base_score=None,\n",
       "                               booster='gbtree', callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=0.7644821944288629, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric='auc',\n",
       "                               feature_types=None, gamma=0.8647062123246894,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=3.9543889166305703,\n",
       "                               learning_rate=0.01221636279037111, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=9,\n",
       "                               max_leaves=None, min_child_weight=6, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=1000, n_jobs=None, ...))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'booster': 'gbtree',\n",
    "            'learning_rate': 0.01221636279037111,\n",
    "            'max_depth': 9,\n",
    "            'min_child_weight': 6,\n",
    "            'subsample': 0.9388323387748934,\n",
    "            'gamma': 0.8647062123246894,\n",
    "            'colsample_bytree': 0.7644821944288629,\n",
    "            'alpha': 0.8375691885584633,\n",
    "            'lambda': 3.9543889166305703,\n",
    "            'scale_pos_weight': 1,\n",
    "            'n_estimators': 1000\n",
    "            }\n",
    "    \n",
    "XGBmodel =ImPipeline([\n",
    "('model', XGBClassifier(**params))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "XGBmodel.fit(train_df, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the Catboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>consumption_diff_sum</th>\n",
       "      <th>consumption_diff_mean</th>\n",
       "      <th>tarif_type_count</th>\n",
       "      <th>reading_remarque_mean</th>\n",
       "      <th>counter_statue_count</th>\n",
       "      <th>counter_coefficient_mean</th>\n",
       "      <th>consommation_level_1_mean</th>\n",
       "      <th>consommation_level_2_mean</th>\n",
       "      <th>consommation_level_3_mean</th>\n",
       "      <th>consommation_level_4_mean</th>\n",
       "      <th>counter_number_nunique</th>\n",
       "      <th>months_number_mean</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>invoice_freq</th>\n",
       "      <th>daily_consumption</th>\n",
       "      <th>client_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>6.810811</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.135135</td>\n",
       "      <td>3.243243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.378378</td>\n",
       "      <td>4967</td>\n",
       "      <td>134.243243</td>\n",
       "      <td>3.660358</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>7.636364</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1091.409091</td>\n",
       "      <td>843.136364</td>\n",
       "      <td>182.318182</td>\n",
       "      <td>586.318182</td>\n",
       "      <td>1</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>3744</td>\n",
       "      <td>170.181818</td>\n",
       "      <td>12.438835</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74</td>\n",
       "      <td>7.459459</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>554.040541</td>\n",
       "      <td>37.364865</td>\n",
       "      <td>15.743243</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5022</td>\n",
       "      <td>67.864865</td>\n",
       "      <td>8.946436</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>6.575000</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2486</td>\n",
       "      <td>62.150000</td>\n",
       "      <td>3.931617</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>301</td>\n",
       "      <td>-116</td>\n",
       "      <td>-2.188679</td>\n",
       "      <td>53</td>\n",
       "      <td>7.905660</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>568.188679</td>\n",
       "      <td>145.056604</td>\n",
       "      <td>33.679245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.528302</td>\n",
       "      <td>5137</td>\n",
       "      <td>96.924528</td>\n",
       "      <td>7.706249</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disrict  client_catg  region  consumption_diff_sum  consumption_diff_mean  \\\n",
       "0       62           11     307                     0               0.000000   \n",
       "1       69           11     103                     0               0.000000   \n",
       "2       62           11     310                     0               0.000000   \n",
       "3       60           11     101                     0               0.000000   \n",
       "4       62           11     301                  -116              -2.188679   \n",
       "\n",
       "   tarif_type_count  reading_remarque_mean  counter_statue_count  \\\n",
       "0                37               6.810811                    37   \n",
       "1                22               7.636364                    22   \n",
       "2                74               7.459459                    74   \n",
       "3                40               6.575000                    40   \n",
       "4                53               7.905660                    53   \n",
       "\n",
       "   counter_coefficient_mean  consommation_level_1_mean  \\\n",
       "0                       1.0                 488.135135   \n",
       "1                       1.0                1091.409091   \n",
       "2                       1.0                 554.040541   \n",
       "3                       1.0                 244.350000   \n",
       "4                       1.0                 568.188679   \n",
       "\n",
       "   consommation_level_2_mean  consommation_level_3_mean  \\\n",
       "0                   3.243243                   0.000000   \n",
       "1                 843.136364                 182.318182   \n",
       "2                  37.364865                  15.743243   \n",
       "3                   0.000000                   0.000000   \n",
       "4                 145.056604                  33.679245   \n",
       "\n",
       "   consommation_level_4_mean  counter_number_nunique  months_number_mean  \\\n",
       "0                   0.000000                       1            4.378378   \n",
       "1                 586.318182                       1            4.545455   \n",
       "2                   0.162162                       2            4.000000   \n",
       "3                   0.000000                       2            3.900000   \n",
       "4                   0.000000                       3            4.528302   \n",
       "\n",
       "   tenure_days  invoice_freq  daily_consumption  client_period  \n",
       "0         4967    134.243243           3.660358             17  \n",
       "1         3744    170.181818          12.438835             10  \n",
       "2         5022     67.864865           8.946436             15  \n",
       "3         2486     62.150000           3.931617             20  \n",
       "4         5137     96.924528           7.706249             42  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-10 22:38:15,405] A new study created in memory with name: no-name-9f0a6c19-e1d1-47ba-bd34-9461685e1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-10 22:40:05,547] Trial 0 finished with value: 0.7603610449234928 and parameters: {'iterations': 500, 'learning_rate': 0.11, 'depth': 9, 'l2_leaf_reg': 0.00327258649050133, 'subsample': 0.8, 'colsample_bylevel': 0.2, 'min_child_samples': 13, 'bagging_temperature': 7.0, 'scale_pos_weight': 10.0, 'border_count': 35}. Best is trial 0 with value: 0.7603610449234928.\n",
      "[I 2023-12-10 22:43:20,987] Trial 1 finished with value: 0.831017819910594 and parameters: {'iterations': 950, 'learning_rate': 0.04, 'depth': 7, 'l2_leaf_reg': 0.2704634533819429, 'subsample': 0.5, 'colsample_bylevel': 0.9, 'min_child_samples': 6, 'bagging_temperature': 1.0, 'scale_pos_weight': 6.0, 'border_count': 145}. Best is trial 1 with value: 0.831017819910594.\n",
      "[I 2023-12-10 22:47:42,963] Trial 2 finished with value: 0.8167361632404825 and parameters: {'iterations': 1550, 'learning_rate': 0.08, 'depth': 5, 'l2_leaf_reg': 0.00284586915899393, 'subsample': 1.0, 'colsample_bylevel': 0.5, 'min_child_samples': 12, 'bagging_temperature': 10.0, 'scale_pos_weight': 9.0, 'border_count': 165}. Best is trial 1 with value: 0.831017819910594.\n",
      "[I 2023-12-10 22:55:10,141] Trial 3 finished with value: 0.778996861089975 and parameters: {'iterations': 1900, 'learning_rate': 0.13, 'depth': 8, 'l2_leaf_reg': 0.6349002804292391, 'subsample': 0.7000000000000001, 'colsample_bylevel': 1.0, 'min_child_samples': 7, 'bagging_temperature': 6.0, 'scale_pos_weight': 9.0, 'border_count': 70}. Best is trial 1 with value: 0.831017819910594.\n",
      "[I 2023-12-10 23:03:46,881] Trial 4 finished with value: 0.7692689130920167 and parameters: {'iterations': 1700, 'learning_rate': 0.27, 'depth': 10, 'l2_leaf_reg': 1.2416650289063502, 'subsample': 0.9, 'colsample_bylevel': 0.6, 'min_child_samples': 13, 'bagging_temperature': 10.0, 'scale_pos_weight': 10.0, 'border_count': 15}. Best is trial 1 with value: 0.831017819910594.\n",
      "[I 2023-12-10 23:07:55,192] Trial 5 finished with value: 0.8187036890364782 and parameters: {'iterations': 950, 'learning_rate': 0.16, 'depth': 8, 'l2_leaf_reg': 7.683494515703463, 'subsample': 0.8, 'colsample_bylevel': 0.5, 'min_child_samples': 15, 'bagging_temperature': 0.0, 'scale_pos_weight': 1.0, 'border_count': 205}. Best is trial 1 with value: 0.831017819910594.\n",
      "[I 2023-12-10 23:11:41,532] Trial 6 finished with value: 0.7899464270706844 and parameters: {'iterations': 1750, 'learning_rate': 0.26, 'depth': 5, 'l2_leaf_reg': 0.11449901960189933, 'subsample': 0.2, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 20, 'bagging_temperature': 0.0, 'scale_pos_weight': 4.0, 'border_count': 20}. Best is trial 1 with value: 0.831017819910594.\n",
      "[I 2023-12-10 23:12:39,262] Trial 7 finished with value: 0.834654365872125 and parameters: {'iterations': 350, 'learning_rate': 0.19, 'depth': 6, 'l2_leaf_reg': 3.3155073145111924, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.9, 'min_child_samples': 4, 'bagging_temperature': 8.0, 'scale_pos_weight': 1.0, 'border_count': 165}. Best is trial 7 with value: 0.834654365872125.\n",
      "[I 2023-12-10 23:18:20,507] Trial 8 finished with value: 0.7511751298741253 and parameters: {'iterations': 1150, 'learning_rate': 0.19, 'depth': 10, 'l2_leaf_reg': 0.013463061864959146, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 7, 'bagging_temperature': 9.0, 'scale_pos_weight': 2.0, 'border_count': 165}. Best is trial 7 with value: 0.834654365872125.\n",
      "[I 2023-12-10 23:20:16,664] Trial 9 finished with value: 0.8262083588852522 and parameters: {'iterations': 350, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 0.00750235983314393, 'subsample': 0.8, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 15, 'bagging_temperature': 9.0, 'scale_pos_weight': 10.0, 'border_count': 225}. Best is trial 7 with value: 0.834654365872125.\n",
      "[I 2023-12-10 23:20:42,464] Trial 10 finished with value: 0.8331598007870775 and parameters: {'iterations': 200, 'learning_rate': 0.21000000000000002, 'depth': 4, 'l2_leaf_reg': 8.12050983324594, 'subsample': 0.1, 'colsample_bylevel': 0.8, 'min_child_samples': 1, 'bagging_temperature': 3.0, 'scale_pos_weight': 4.0, 'border_count': 95}. Best is trial 7 with value: 0.834654365872125.\n",
      "[I 2023-12-10 23:20:48,749] Trial 11 finished with value: 0.829608024691353 and parameters: {'iterations': 100, 'learning_rate': 0.21000000000000002, 'depth': 4, 'l2_leaf_reg': 8.810452494341911, 'subsample': 0.1, 'colsample_bylevel': 0.8, 'min_child_samples': 1, 'bagging_temperature': 3.0, 'scale_pos_weight': 4.0, 'border_count': 105}. Best is trial 7 with value: 0.834654365872125.\n",
      "[I 2023-12-10 23:22:15,139] Trial 12 finished with value: 0.820768913083894 and parameters: {'iterations': 550, 'learning_rate': 0.22, 'depth': 6, 'l2_leaf_reg': 1.675886712618471, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.7000000000000001, 'min_child_samples': 1, 'bagging_temperature': 4.0, 'scale_pos_weight': 3.0, 'border_count': 105}. Best is trial 7 with value: 0.834654365872125.\n",
      "[I 2023-12-10 23:22:23,268] Trial 13 finished with value: 0.8335576925580325 and parameters: {'iterations': 100, 'learning_rate': 0.29000000000000004, 'depth': 4, 'l2_leaf_reg': 3.42403781365499, 'subsample': 0.4, 'colsample_bylevel': 1.0, 'min_child_samples': 4, 'bagging_temperature': 3.0, 'scale_pos_weight': 6.0, 'border_count': 250}. Best is trial 7 with value: 0.834654365872125.\n",
      "[I 2023-12-10 23:24:33,780] Trial 14 finished with value: 0.7945313863023888 and parameters: {'iterations': 700, 'learning_rate': 0.3, 'depth': 6, 'l2_leaf_reg': 2.3067616575597256, 'subsample': 0.4, 'colsample_bylevel': 1.0, 'min_child_samples': 5, 'bagging_temperature': 7.0, 'scale_pos_weight': 7.0, 'border_count': 255}. Best is trial 7 with value: 0.834654365872125.\n",
      "[I 2023-12-10 23:24:44,798] Trial 15 finished with value: 0.8352115960263141 and parameters: {'iterations': 100, 'learning_rate': 0.25, 'depth': 5, 'l2_leaf_reg': 0.32597677622078686, 'subsample': 0.4, 'colsample_bylevel': 1.0, 'min_child_samples': 9, 'bagging_temperature': 5.0, 'scale_pos_weight': 7.0, 'border_count': 200}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:30:01,279] Trial 16 finished with value: 0.7843342473967908 and parameters: {'iterations': 1250, 'learning_rate': 0.24000000000000002, 'depth': 6, 'l2_leaf_reg': 0.450167653727776, 'subsample': 0.5, 'colsample_bylevel': 0.8, 'min_child_samples': 10, 'bagging_temperature': 5.0, 'scale_pos_weight': 7.0, 'border_count': 190}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:32:21,938] Trial 17 finished with value: 0.8307719494127415 and parameters: {'iterations': 700, 'learning_rate': 0.16, 'depth': 5, 'l2_leaf_reg': 0.05514285942053678, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.9, 'min_child_samples': 9, 'bagging_temperature': 7.0, 'scale_pos_weight': 1.0, 'border_count': 190}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:34:34,903] Trial 18 finished with value: 0.8072350448831909 and parameters: {'iterations': 350, 'learning_rate': 0.17, 'depth': 7, 'l2_leaf_reg': 0.1885418955009216, 'subsample': 0.6, 'colsample_bylevel': 0.6, 'min_child_samples': 3, 'bagging_temperature': 8.0, 'scale_pos_weight': 8.0, 'border_count': 150}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:36:02,654] Trial 19 finished with value: 0.8170063032228173 and parameters: {'iterations': 350, 'learning_rate': 0.26, 'depth': 6, 'l2_leaf_reg': 0.9764764081548744, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.9, 'min_child_samples': 8, 'bagging_temperature': 5.0, 'scale_pos_weight': 5.0, 'border_count': 220}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:39:35,732] Trial 20 finished with value: 0.782984726154925 and parameters: {'iterations': 850, 'learning_rate': 0.19, 'depth': 7, 'l2_leaf_reg': 0.05138393036796965, 'subsample': 0.2, 'colsample_bylevel': 0.7000000000000001, 'min_child_samples': 19, 'bagging_temperature': 6.0, 'scale_pos_weight': 2.0, 'border_count': 185}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:39:48,808] Trial 21 finished with value: 0.8341704172865014 and parameters: {'iterations': 100, 'learning_rate': 0.3, 'depth': 4, 'l2_leaf_reg': 2.9785349830187244, 'subsample': 0.4, 'colsample_bylevel': 1.0, 'min_child_samples': 4, 'bagging_temperature': 2.0, 'scale_pos_weight': 6.0, 'border_count': 250}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:40:55,511] Trial 22 finished with value: 0.8317651828701083 and parameters: {'iterations': 250, 'learning_rate': 0.24000000000000002, 'depth': 5, 'l2_leaf_reg': 3.228641569968686, 'subsample': 0.4, 'colsample_bylevel': 1.0, 'min_child_samples': 3, 'bagging_temperature': 2.0, 'scale_pos_weight': 7.0, 'border_count': 230}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:42:32,493] Trial 23 finished with value: 0.824682535244999 and parameters: {'iterations': 500, 'learning_rate': 0.28, 'depth': 4, 'l2_leaf_reg': 0.4869470492028199, 'subsample': 0.6, 'colsample_bylevel': 0.9, 'min_child_samples': 5, 'bagging_temperature': 4.0, 'scale_pos_weight': 5.0, 'border_count': 235}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:43:09,838] Trial 24 finished with value: 0.8315872755670435 and parameters: {'iterations': 200, 'learning_rate': 0.24000000000000002, 'depth': 5, 'l2_leaf_reg': 0.8916565319599467, 'subsample': 0.2, 'colsample_bylevel': 1.0, 'min_child_samples': 3, 'bagging_temperature': 2.0, 'scale_pos_weight': 8.0, 'border_count': 205}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:43:25,812] Trial 25 finished with value: 0.8336902064298661 and parameters: {'iterations': 100, 'learning_rate': 0.3, 'depth': 4, 'l2_leaf_reg': 3.2585769092627235, 'subsample': 0.4, 'colsample_bylevel': 0.7000000000000001, 'min_child_samples': 11, 'bagging_temperature': 6.0, 'scale_pos_weight': 6.0, 'border_count': 125}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:45:23,211] Trial 26 finished with value: 0.8191602033416062 and parameters: {'iterations': 650, 'learning_rate': 0.24000000000000002, 'depth': 5, 'l2_leaf_reg': 1.7391635277954625, 'subsample': 0.5, 'colsample_bylevel': 0.9, 'min_child_samples': 9, 'bagging_temperature': 4.0, 'scale_pos_weight': 8.0, 'border_count': 170}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:46:22,095] Trial 27 finished with value: 0.8304031639400744 and parameters: {'iterations': 350, 'learning_rate': 0.13, 'depth': 6, 'l2_leaf_reg': 0.34362707493338523, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.8, 'min_child_samples': 6, 'bagging_temperature': 1.0, 'scale_pos_weight': 5.0, 'border_count': 210}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:49:46,658] Trial 28 finished with value: 0.8239586656260196 and parameters: {'iterations': 1400, 'learning_rate': 0.18000000000000002, 'depth': 5, 'l2_leaf_reg': 4.5366194928179935, 'subsample': 0.2, 'colsample_bylevel': 1.0, 'min_child_samples': 4, 'bagging_temperature': 8.0, 'scale_pos_weight': 3.0, 'border_count': 250}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:51:44,819] Trial 29 finished with value: 0.8176698523375956 and parameters: {'iterations': 500, 'learning_rate': 0.09, 'depth': 8, 'l2_leaf_reg': 0.7379109058544934, 'subsample': 0.6, 'colsample_bylevel': 0.9, 'min_child_samples': 14, 'bagging_temperature': 5.0, 'scale_pos_weight': 7.0, 'border_count': 65}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:52:29,282] Trial 30 finished with value: 0.8252730110181243 and parameters: {'iterations': 250, 'learning_rate': 0.22, 'depth': 7, 'l2_leaf_reg': 1.4551787981508917, 'subsample': 0.4, 'colsample_bylevel': 0.2, 'min_child_samples': 8, 'bagging_temperature': 8.0, 'scale_pos_weight': 3.0, 'border_count': 125}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:52:37,747] Trial 31 finished with value: 0.8334359156017414 and parameters: {'iterations': 100, 'learning_rate': 0.3, 'depth': 4, 'l2_leaf_reg': 5.032464916533087, 'subsample': 0.4, 'colsample_bylevel': 0.7000000000000001, 'min_child_samples': 11, 'bagging_temperature': 6.0, 'scale_pos_weight': 6.0, 'border_count': 130}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:52:46,501] Trial 32 finished with value: 0.8332297517971389 and parameters: {'iterations': 100, 'learning_rate': 0.28, 'depth': 4, 'l2_leaf_reg': 3.268073967834822, 'subsample': 0.5, 'colsample_bylevel': 0.8, 'min_child_samples': 11, 'bagging_temperature': 6.0, 'scale_pos_weight': 6.0, 'border_count': 155}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:53:44,166] Trial 33 finished with value: 0.8304485849060562 and parameters: {'iterations': 450, 'learning_rate': 0.26, 'depth': 4, 'l2_leaf_reg': 1.8816805277840543, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.7000000000000001, 'min_child_samples': 16, 'bagging_temperature': 7.0, 'scale_pos_weight': 5.0, 'border_count': 140}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:54:25,224] Trial 34 finished with value: 0.828767767861003 and parameters: {'iterations': 250, 'learning_rate': 0.3, 'depth': 5, 'l2_leaf_reg': 2.3614289572467664, 'subsample': 0.5, 'colsample_bylevel': 0.9, 'min_child_samples': 12, 'bagging_temperature': 9.0, 'scale_pos_weight': 6.0, 'border_count': 180}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:55:19,184] Trial 35 finished with value: 0.8311624304988119 and parameters: {'iterations': 400, 'learning_rate': 0.28, 'depth': 4, 'l2_leaf_reg': 5.5060672072085275, 'subsample': 0.4, 'colsample_bylevel': 1.0, 'min_child_samples': 6, 'bagging_temperature': 7.0, 'scale_pos_weight': 9.0, 'border_count': 85}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:56:41,287] Trial 36 finished with value: 0.8340862332163892 and parameters: {'iterations': 600, 'learning_rate': 0.12, 'depth': 5, 'l2_leaf_reg': 0.8898287006808899, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.4, 'min_child_samples': 10, 'bagging_temperature': 1.0, 'scale_pos_weight': 7.0, 'border_count': 120}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-10 23:58:39,096] Trial 37 finished with value: 0.8188629662392348 and parameters: {'iterations': 800, 'learning_rate': 0.14, 'depth': 6, 'l2_leaf_reg': 0.7243047470671116, 'subsample': 0.2, 'colsample_bylevel': 0.4, 'min_child_samples': 9, 'bagging_temperature': 1.0, 'scale_pos_weight': 8.0, 'border_count': 205}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-11 00:00:14,843] Trial 38 finished with value: 0.8320356511585871 and parameters: {'iterations': 600, 'learning_rate': 0.09999999999999999, 'depth': 5, 'l2_leaf_reg': 0.24953058458305521, 'subsample': 1.0, 'colsample_bylevel': 0.4, 'min_child_samples': 7, 'bagging_temperature': 0.0, 'scale_pos_weight': 9.0, 'border_count': 60}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-11 00:02:07,171] Trial 39 finished with value: 0.8339077388395791 and parameters: {'iterations': 950, 'learning_rate': 0.06999999999999999, 'depth': 7, 'l2_leaf_reg': 1.0344380600119172, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.1, 'min_child_samples': 2, 'bagging_temperature': 1.0, 'scale_pos_weight': 7.0, 'border_count': 170}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-11 00:03:54,745] Trial 40 finished with value: 0.8329280793508218 and parameters: {'iterations': 800, 'learning_rate': 0.060000000000000005, 'depth': 6, 'l2_leaf_reg': 0.5485169984209969, 'subsample': 0.1, 'colsample_bylevel': 0.4, 'min_child_samples': 5, 'bagging_temperature': 2.0, 'scale_pos_weight': 8.0, 'border_count': 115}. Best is trial 15 with value: 0.8352115960263141.\n",
      "[I 2023-12-11 00:06:04,841] Trial 41 finished with value: 0.8357035523968033 and parameters: {'iterations': 1050, 'learning_rate': 0.05, 'depth': 7, 'l2_leaf_reg': 1.268651344928031, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.1, 'min_child_samples': 2, 'bagging_temperature': 1.0, 'scale_pos_weight': 7.0, 'border_count': 170}. Best is trial 41 with value: 0.8357035523968033.\n",
      "[I 2023-12-11 00:09:17,561] Trial 42 finished with value: 0.8359383872990989 and parameters: {'iterations': 1100, 'learning_rate': 0.03, 'depth': 7, 'l2_leaf_reg': 1.2434876153792471, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.1, 'min_child_samples': 2, 'bagging_temperature': 0.0, 'scale_pos_weight': 7.0, 'border_count': 145}. Best is trial 42 with value: 0.8359383872990989.\n",
      "[I 2023-12-11 00:12:13,603] Trial 43 finished with value: 0.8360482887203023 and parameters: {'iterations': 1050, 'learning_rate': 0.03, 'depth': 8, 'l2_leaf_reg': 1.304508314744491, 'subsample': 0.2, 'colsample_bylevel': 0.1, 'min_child_samples': 2, 'bagging_temperature': 2.0, 'scale_pos_weight': 6.0, 'border_count': 140}. Best is trial 43 with value: 0.8360482887203023.\n",
      "[I 2023-12-11 00:15:31,502] Trial 44 finished with value: 0.834720198911824 and parameters: {'iterations': 1150, 'learning_rate': 0.02, 'depth': 8, 'l2_leaf_reg': 1.199381993182978, 'subsample': 0.2, 'colsample_bylevel': 0.1, 'min_child_samples': 2, 'bagging_temperature': 0.0, 'scale_pos_weight': 7.0, 'border_count': 140}. Best is trial 43 with value: 0.8360482887203023.\n",
      "[I 2023-12-11 00:18:04,573] Trial 45 finished with value: 0.8300197585616719 and parameters: {'iterations': 1150, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 1.2939794213576303, 'subsample': 0.2, 'colsample_bylevel': 0.1, 'min_child_samples': 2, 'bagging_temperature': 0.0, 'scale_pos_weight': 7.0, 'border_count': 145}. Best is trial 43 with value: 0.8360482887203023.\n",
      "[I 2023-12-11 00:22:09,607] Trial 46 finished with value: 0.8250347328199605 and parameters: {'iterations': 1450, 'learning_rate': 0.03, 'depth': 8, 'l2_leaf_reg': 0.3436438411220293, 'subsample': 0.2, 'colsample_bylevel': 0.2, 'min_child_samples': 2, 'bagging_temperature': 0.0, 'scale_pos_weight': 9.0, 'border_count': 145}. Best is trial 43 with value: 0.8360482887203023.\n",
      "[I 2023-12-11 00:24:35,867] Trial 47 finished with value: 0.8332149349178266 and parameters: {'iterations': 1100, 'learning_rate': 0.04, 'depth': 9, 'l2_leaf_reg': 1.269243871009953, 'subsample': 0.1, 'colsample_bylevel': 0.1, 'min_child_samples': 1, 'bagging_temperature': 0.0, 'scale_pos_weight': 8.0, 'border_count': 160}. Best is trial 43 with value: 0.8360482887203023.\n",
      "[I 2023-12-11 00:28:01,217] Trial 48 finished with value: 0.8230853229545987 and parameters: {'iterations': 1300, 'learning_rate': 0.04, 'depth': 8, 'l2_leaf_reg': 0.5221919560996102, 'subsample': 0.1, 'colsample_bylevel': 0.2, 'min_child_samples': 2, 'bagging_temperature': 1.0, 'scale_pos_weight': 7.0, 'border_count': 135}. Best is trial 43 with value: 0.8360482887203023.\n",
      "[I 2023-12-11 00:31:26,922] Trial 49 finished with value: 0.8365528188980059 and parameters: {'iterations': 1650, 'learning_rate': 0.03, 'depth': 8, 'l2_leaf_reg': 1.6833165213557069, 'subsample': 0.2, 'colsample_bylevel': 0.1, 'min_child_samples': 3, 'bagging_temperature': 0.0, 'scale_pos_weight': 6.0, 'border_count': 180}. Best is trial 49 with value: 0.8365528188980059.\n",
      "[I 2023-12-11 00:38:25,434] Trial 50 finished with value: 0.7990259586219517 and parameters: {'iterations': 1900, 'learning_rate': 0.060000000000000005, 'depth': 9, 'l2_leaf_reg': 2.1117578393842877, 'subsample': 0.1, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 3, 'bagging_temperature': 3.0, 'scale_pos_weight': 6.0, 'border_count': 175}. Best is trial 49 with value: 0.8365528188980059.\n",
      "[I 2023-12-11 00:42:48,864] Trial 51 finished with value: 0.8362540339632872 and parameters: {'iterations': 1600, 'learning_rate': 0.02, 'depth': 8, 'l2_leaf_reg': 1.2936154534396547, 'subsample': 0.2, 'colsample_bylevel': 0.1, 'min_child_samples': 1, 'bagging_temperature': 0.0, 'scale_pos_weight': 7.0, 'border_count': 195}. Best is trial 49 with value: 0.8365528188980059.\n",
      "[I 2023-12-11 00:47:03,629] Trial 52 finished with value: 0.8345901894134327 and parameters: {'iterations': 1650, 'learning_rate': 0.05, 'depth': 7, 'l2_leaf_reg': 0.7160591977245474, 'subsample': 0.2, 'colsample_bylevel': 0.1, 'min_child_samples': 1, 'bagging_temperature': 0.0, 'scale_pos_weight': 5.0, 'border_count': 195}. Best is trial 49 with value: 0.8365528188980059.\n",
      "[I 2023-12-11 00:54:14,679] Trial 53 finished with value: 0.8334485810306594 and parameters: {'iterations': 2000, 'learning_rate': 0.02, 'depth': 8, 'l2_leaf_reg': 1.9156273229114513, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.2, 'min_child_samples': 4, 'bagging_temperature': 1.0, 'scale_pos_weight': 6.0, 'border_count': 195}. Best is trial 49 with value: 0.8365528188980059.\n",
      "[I 2023-12-11 00:57:37,647] Trial 54 finished with value: 0.8371048232163696 and parameters: {'iterations': 1550, 'learning_rate': 0.03, 'depth': 8, 'l2_leaf_reg': 1.401662249131566, 'subsample': 0.30000000000000004, 'colsample_bylevel': 0.1, 'min_child_samples': 1, 'bagging_temperature': 1.0, 'scale_pos_weight': 4.0, 'border_count': 155}. Best is trial 54 with value: 0.8371048232163696.\n",
      "[I 2023-12-11 01:01:36,187] Trial 55 finished with value: 0.8385740658527444 and parameters: {'iterations': 1600, 'learning_rate': 0.03, 'depth': 8, 'l2_leaf_reg': 6.660193763884572, 'subsample': 0.9, 'colsample_bylevel': 0.1, 'min_child_samples': 1, 'bagging_temperature': 2.0, 'scale_pos_weight': 4.0, 'border_count': 160}. Best is trial 55 with value: 0.8385740658527444.\n",
      "[I 2023-12-11 01:07:17,143] Trial 56 finished with value: 0.8388830176994535 and parameters: {'iterations': 1600, 'learning_rate': 0.02, 'depth': 8, 'l2_leaf_reg': 9.821267848909821, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.2, 'min_child_samples': 1, 'bagging_temperature': 2.0, 'scale_pos_weight': 4.0, 'border_count': 160}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 01:15:33,002] Trial 57 finished with value: 0.8379092423932748 and parameters: {'iterations': 1600, 'learning_rate': 0.01, 'depth': 8, 'l2_leaf_reg': 7.775584838308665, 'subsample': 0.9, 'colsample_bylevel': 0.2, 'min_child_samples': 1, 'bagging_temperature': 2.0, 'scale_pos_weight': 4.0, 'border_count': 160}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 01:25:15,619] Trial 58 finished with value: 0.8384928686311814 and parameters: {'iterations': 1600, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 9.096358314029382, 'subsample': 0.9, 'colsample_bylevel': 0.2, 'min_child_samples': 1, 'bagging_temperature': 2.0, 'scale_pos_weight': 4.0, 'border_count': 160}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 01:34:31,857] Trial 59 finished with value: 0.8388469811893033 and parameters: {'iterations': 1750, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 9.402946721440061, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 3, 'bagging_temperature': 3.0, 'scale_pos_weight': 4.0, 'border_count': 160}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 01:46:31,251] Trial 60 finished with value: 0.837805302686176 and parameters: {'iterations': 1800, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 8.097918799239745, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 1, 'bagging_temperature': 3.0, 'scale_pos_weight': 4.0, 'border_count': 165}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 02:00:32,179] Trial 61 finished with value: 0.8378779714166058 and parameters: {'iterations': 1800, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 9.882267970239962, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 1, 'bagging_temperature': 3.0, 'scale_pos_weight': 4.0, 'border_count': 160}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 02:13:41,359] Trial 62 finished with value: 0.8380390275428609 and parameters: {'iterations': 1800, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 8.165690758017732, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 1, 'bagging_temperature': 3.0, 'scale_pos_weight': 3.0, 'border_count': 160}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 02:26:55,487] Trial 63 finished with value: 0.8386884367606257 and parameters: {'iterations': 1800, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 9.652272083122961, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 3, 'bagging_temperature': 4.0, 'scale_pos_weight': 3.0, 'border_count': 155}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 02:36:04,227] Trial 64 finished with value: 0.8384243953412203 and parameters: {'iterations': 1450, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 6.77145452905033, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 3, 'bagging_temperature': 4.0, 'scale_pos_weight': 3.0, 'border_count': 155}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 02:48:11,138] Trial 65 finished with value: 0.8126437639817331 and parameters: {'iterations': 1750, 'learning_rate': 0.05, 'depth': 10, 'l2_leaf_reg': 6.127418151332145, 'subsample': 0.8, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 5, 'bagging_temperature': 4.0, 'scale_pos_weight': 3.0, 'border_count': 110}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 02:58:26,203] Trial 66 finished with value: 0.8382632586520821 and parameters: {'iterations': 1450, 'learning_rate': 0.02, 'depth': 9, 'l2_leaf_reg': 9.94836493499903, 'subsample': 0.8, 'colsample_bylevel': 0.5, 'min_child_samples': 3, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 180}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 03:08:10,472] Trial 67 finished with value: 0.829086820832919 and parameters: {'iterations': 1400, 'learning_rate': 0.04, 'depth': 9, 'l2_leaf_reg': 4.398631281481047, 'subsample': 0.8, 'colsample_bylevel': 0.5, 'min_child_samples': 3, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 180}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 03:16:25,985] Trial 68 finished with value: 0.8196612282468058 and parameters: {'iterations': 1500, 'learning_rate': 0.08, 'depth': 9, 'l2_leaf_reg': 9.901824154613054, 'subsample': 1.0, 'colsample_bylevel': 0.2, 'min_child_samples': 4, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 215}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 03:26:54,324] Trial 69 finished with value: 0.837833956828737 and parameters: {'iterations': 1300, 'learning_rate': 0.02, 'depth': 9, 'l2_leaf_reg': 6.026680281829209, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.5, 'min_child_samples': 6, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 185}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 03:40:06,574] Trial 70 finished with value: 0.8199463919097847 and parameters: {'iterations': 1900, 'learning_rate': 0.060000000000000005, 'depth': 9, 'l2_leaf_reg': 4.004250540782644, 'subsample': 0.8, 'colsample_bylevel': 0.6, 'min_child_samples': 4, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 150}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 03:51:39,466] Trial 71 finished with value: 0.8381323614713162 and parameters: {'iterations': 1700, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 6.845922569445115, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 3, 'bagging_temperature': 3.0, 'scale_pos_weight': 3.0, 'border_count': 155}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 04:00:33,762] Trial 72 finished with value: 0.8371449427475041 and parameters: {'iterations': 1700, 'learning_rate': 0.02, 'depth': 9, 'l2_leaf_reg': 7.051713509962191, 'subsample': 1.0, 'colsample_bylevel': 0.2, 'min_child_samples': 3, 'bagging_temperature': 3.0, 'scale_pos_weight': 3.0, 'border_count': 170}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 04:09:18,371] Trial 73 finished with value: 0.8020465240963173 and parameters: {'iterations': 1550, 'learning_rate': 0.04, 'depth': 10, 'l2_leaf_reg': 6.0386479519707965, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 3, 'bagging_temperature': 3.0, 'scale_pos_weight': 3.0, 'border_count': 5}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 04:21:24,390] Trial 74 finished with value: 0.8287141657529562 and parameters: {'iterations': 1700, 'learning_rate': 0.02, 'depth': 10, 'l2_leaf_reg': 4.514562301259003, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.4, 'min_child_samples': 5, 'bagging_temperature': 5.0, 'scale_pos_weight': 4.0, 'border_count': 130}. Best is trial 56 with value: 0.8388830176994535.\n",
      "[I 2023-12-11 04:32:31,855] Trial 75 finished with value: 0.8394281819451365 and parameters: {'iterations': 2000, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 9.736531689548219, 'subsample': 0.8, 'colsample_bylevel': 0.2, 'min_child_samples': 4, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 150}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 04:42:34,024] Trial 76 finished with value: 0.8343452189559037 and parameters: {'iterations': 2000, 'learning_rate': 0.03, 'depth': 9, 'l2_leaf_reg': 9.025401862539066, 'subsample': 0.8, 'colsample_bylevel': 0.2, 'min_child_samples': 4, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 150}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 04:53:03,905] Trial 77 finished with value: 0.8346483238672929 and parameters: {'iterations': 1950, 'learning_rate': 0.02, 'depth': 9, 'l2_leaf_reg': 5.045487227355935, 'subsample': 0.8, 'colsample_bylevel': 0.2, 'min_child_samples': 2, 'bagging_temperature': 5.0, 'scale_pos_weight': 4.0, 'border_count': 185}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 05:02:21,648] Trial 78 finished with value: 0.8221793679695495 and parameters: {'iterations': 1850, 'learning_rate': 0.05, 'depth': 9, 'l2_leaf_reg': 3.925855914416064, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.2, 'min_child_samples': 17, 'bagging_temperature': 5.0, 'scale_pos_weight': 2.0, 'border_count': 175}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 05:12:19,137] Trial 79 finished with value: 0.8250501416553755 and parameters: {'iterations': 1450, 'learning_rate': 0.04, 'depth': 10, 'l2_leaf_reg': 9.983299936244402, 'subsample': 1.0, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 3, 'bagging_temperature': 4.0, 'scale_pos_weight': 3.0, 'border_count': 135}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 05:23:43,869] Trial 80 finished with value: 0.8389691379169474 and parameters: {'iterations': 1850, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 6.915253796775143, 'subsample': 0.8, 'colsample_bylevel': 0.4, 'min_child_samples': 5, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 05:34:56,250] Trial 81 finished with value: 0.839050806588918 and parameters: {'iterations': 1750, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 6.778697166083089, 'subsample': 0.8, 'colsample_bylevel': 0.4, 'min_child_samples': 5, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 05:46:08,115] Trial 82 finished with value: 0.8390711208589714 and parameters: {'iterations': 1850, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 6.570558177182912, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.4, 'min_child_samples': 7, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 05:59:32,325] Trial 83 finished with value: 0.8390469338458129 and parameters: {'iterations': 1900, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 5.523548690175516, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.4, 'min_child_samples': 7, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 06:12:49,561] Trial 84 finished with value: 0.8281046800045575 and parameters: {'iterations': 1850, 'learning_rate': 0.03, 'depth': 10, 'l2_leaf_reg': 2.626256353573553, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.4, 'min_child_samples': 7, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 06:26:34,570] Trial 85 finished with value: 0.8306179045655162 and parameters: {'iterations': 1950, 'learning_rate': 0.03, 'depth': 10, 'l2_leaf_reg': 5.6006407083694425, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.4, 'min_child_samples': 7, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 170}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 06:39:20,750] Trial 86 finished with value: 0.8384381051809155 and parameters: {'iterations': 1850, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 3.5902792523411478, 'subsample': 0.6, 'colsample_bylevel': 0.4, 'min_child_samples': 8, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 150}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 06:51:49,543] Trial 87 finished with value: 0.8360958583732995 and parameters: {'iterations': 1750, 'learning_rate': 0.02, 'depth': 10, 'l2_leaf_reg': 5.088487156327952, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.4, 'min_child_samples': 6, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 175}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 07:03:07,120] Trial 88 finished with value: 0.8310494578315678 and parameters: {'iterations': 1950, 'learning_rate': 0.04, 'depth': 9, 'l2_leaf_reg': 7.395172767084144, 'subsample': 0.8, 'colsample_bylevel': 0.5, 'min_child_samples': 5, 'bagging_temperature': 3.0, 'scale_pos_weight': 1.0, 'border_count': 140}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 07:16:34,405] Trial 89 finished with value: 0.8044187739620497 and parameters: {'iterations': 1900, 'learning_rate': 0.06999999999999999, 'depth': 10, 'l2_leaf_reg': 2.7638153004481936, 'subsample': 0.6, 'colsample_bylevel': 0.6, 'min_child_samples': 6, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 125}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 07:26:53,567] Trial 90 finished with value: 0.8335741036935012 and parameters: {'iterations': 1800, 'learning_rate': 0.03, 'depth': 9, 'l2_leaf_reg': 3.4733369025573695, 'subsample': 0.8, 'colsample_bylevel': 0.4, 'min_child_samples': 6, 'bagging_temperature': 3.0, 'scale_pos_weight': 1.0, 'border_count': 190}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 07:36:34,890] Trial 91 finished with value: 0.8388298327945453 and parameters: {'iterations': 1650, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 7.643855651142206, 'subsample': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 5, 'bagging_temperature': 2.0, 'scale_pos_weight': 2.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 07:45:24,725] Trial 92 finished with value: 0.8387439923944278 and parameters: {'iterations': 1650, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 6.588693126492318, 'subsample': 0.8, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 8, 'bagging_temperature': 1.0, 'scale_pos_weight': 2.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 07:55:15,644] Trial 93 finished with value: 0.8388356923041627 and parameters: {'iterations': 1750, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 5.045984574212071, 'subsample': 0.8, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 7, 'bagging_temperature': 1.0, 'scale_pos_weight': 2.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 08:04:58,249] Trial 94 finished with value: 0.8363092540602303 and parameters: {'iterations': 1650, 'learning_rate': 0.02, 'depth': 9, 'l2_leaf_reg': 4.5241519134018064, 'subsample': 0.8, 'colsample_bylevel': 0.4, 'min_child_samples': 8, 'bagging_temperature': 1.0, 'scale_pos_weight': 2.0, 'border_count': 175}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 08:14:01,725] Trial 95 finished with value: 0.8389343420707693 and parameters: {'iterations': 1750, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 5.706383712795223, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.30000000000000004, 'min_child_samples': 8, 'bagging_temperature': 1.0, 'scale_pos_weight': 1.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 08:23:52,840] Trial 96 finished with value: 0.8377807590042323 and parameters: {'iterations': 1750, 'learning_rate': 0.02, 'depth': 9, 'l2_leaf_reg': 4.8742880979846435, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.5, 'min_child_samples': 7, 'bagging_temperature': 1.0, 'scale_pos_weight': 1.0, 'border_count': 145}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 08:33:58,150] Trial 97 finished with value: 0.838900803311877 and parameters: {'iterations': 1850, 'learning_rate': 0.01, 'depth': 9, 'l2_leaf_reg': 2.978935129211615, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.4, 'min_child_samples': 5, 'bagging_temperature': 2.0, 'scale_pos_weight': 1.0, 'border_count': 165}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 08:44:43,017] Trial 98 finished with value: 0.8269630422784641 and parameters: {'iterations': 2000, 'learning_rate': 0.04, 'depth': 9, 'l2_leaf_reg': 2.774294996419565, 'subsample': 0.6, 'colsample_bylevel': 0.4, 'min_child_samples': 6, 'bagging_temperature': 1.0, 'scale_pos_weight': 1.0, 'border_count': 150}. Best is trial 75 with value: 0.8394281819451365.\n",
      "[I 2023-12-11 08:55:07,638] Trial 99 finished with value: 0.8371396744704169 and parameters: {'iterations': 1850, 'learning_rate': 0.02, 'depth': 9, 'l2_leaf_reg': 3.2072962450309817, 'subsample': 0.7000000000000001, 'colsample_bylevel': 0.4, 'min_child_samples': 7, 'bagging_temperature': 1.0, 'scale_pos_weight': 1.0, 'border_count': 185}. Best is trial 75 with value: 0.8394281819451365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iterations': 2000, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 9.736531689548219, 'subsample': 0.8, 'colsample_bylevel': 0.2, 'min_child_samples': 4, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 150}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def objective(trial,X,y):\n",
    " # 'is_unbalance':True,\n",
    "    cat_params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 2000, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, step=0.01),\n",
    "        'depth': trial.suggest_int('depth', 4, 10, step=1),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0, step=0.1),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0, step=0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20, step=1),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 10, step=1),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10, step=1),\n",
    "        'border_count': trial.suggest_int('border_count', 5, 255, step=5),\n",
    "        'eval_metric': 'AUC'\n",
    "    }\n",
    "\n",
    "    # Create and train the CatBoostClassifier\n",
    "    model = CatBoostClassifier(**cat_params, random_state=42, verbose=0)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(agg_train, target)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=10, n_jobs=-1, scoring=\"roc_auc\")\n",
    "    score = np.mean(cv_scores)\n",
    "    # scorestd = cv_scores.std()\n",
    "    return score  # Replace with appropriate metric\n",
    "\n",
    "# Create a study object and specify the direction is 'maximize'.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Start the optimization\n",
    "study.optimize(lambda trial: objective(trial, agg_train, target), n_trials=100,  gc_after_trial=True)\n",
    "\n",
    "# Print the optimal parameters\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iterations': 2000, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 9.736531689548219, 'subsample': 0.8, 'colsample_bylevel': 0.2, 'min_child_samples': 4, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 150}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)\n",
    "# Best is trial 75 with value: 0.8394281819451365. {'iterations': 2000, 'learning_rate': 0.01, 'depth': 10, 'l2_leaf_reg': 9.736531689548219, 'subsample': 0.8, 'colsample_bylevel': 0.2, 'min_child_samples': 4, 'bagging_temperature': 4.0, 'scale_pos_weight': 2.0, 'border_count': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2386dbddb50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "        'iterations': 2000,\n",
    "        'learning_rate': 0.01,\n",
    "        'depth': 10,\n",
    "        'l2_leaf_reg': 9.736531689548219,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bylevel': 0.2,\n",
    "        'min_child_samples': 4,\n",
    "        'bagging_temperature': 4.0,\n",
    "        'scale_pos_weight': 2.0,\n",
    "        'border_count': 150,\n",
    "        'eval_metric': 'AUC'\n",
    "    }\n",
    "\n",
    "    # Create and train the CatBoostClassifier\n",
    "model = CatBoostClassifier(**params, random_state=42, verbose=0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(agg_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = XGBmodel.predict_proba(test_df)\n",
    "preds = pd.DataFrame(pred, columns=['target','target2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(preds, columns=['target2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target2\n",
       "0  0.016889\n",
       "1  0.118035\n",
       "2  0.005813\n",
       "3  0.005299\n",
       "4  0.030420"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58069, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_test = pd.read_csv(\"C:/Users/Asus/Documents/MMAI/869_MachineLearningAI/Team_assignment/test/client_test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58069, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_Client_0</td>\n",
       "      <td>0.016889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_Client_1</td>\n",
       "      <td>0.118035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_Client_10</td>\n",
       "      <td>0.005813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_Client_100</td>\n",
       "      <td>0.005299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_Client_1000</td>\n",
       "      <td>0.030420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          client_id    target\n",
       "0     test_Client_0  0.016889\n",
       "1     test_Client_1  0.118035\n",
       "2    test_Client_10  0.005813\n",
       "3   test_Client_100  0.005299\n",
       "4  test_Client_1000  0.030420"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        'client_id': client_test['client_id'],\n",
    "        'target': preds['target2']\n",
    "    }\n",
    ")\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"C:/Users/Asus/Documents/MMAI/869_MachineLearningAI/Team_assignment/submissionXGB_Final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58069, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "costData = pd.DataFrame([[2500,20000],[500,0]], index=['Actual Fail', 'Actual No Fail'],columns=['Predicted Fail','Predicted No Fail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Fail</th>\n",
       "      <th>Predicted No Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Fail</th>\n",
       "      <td>2500</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual No Fail</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Fail  Predicted No Fail\n",
       "Actual Fail               2500              20000\n",
       "Actual No Fail             500                  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted Fail        527500\n",
       "Predicted No Fail    1100000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfCostData = pd.DataFrame([[201*2500,55*20000],[50*500,0]], index=['Actual Fail', 'Actual No Fail'],columns=['Predicted Fail','Predicted No Fail'])\n",
    "\n",
    "#The total cost after using the RandomForest model\n",
    "rfCostData.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Fail</th>\n",
       "      <th>Predicted No Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Fail</th>\n",
       "      <td>502500</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual No Fail</th>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Fail  Predicted No Fail\n",
       "Actual Fail             502500            1100000\n",
       "Actual No Fail           25000                  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfCostData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted Fail       1165000\n",
       "Predicted No Fail     600000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cost from RNN model\n",
    "rnnCostData = pd.DataFrame([[226*2500,30*20000],[1200*500,0]], index=['Actual Fail', 'Actual No Fail'],columns=['Predicted Fail','Predicted No Fail'])\n",
    "\n",
    "#The total cost after using the RNN model\n",
    "rnnCostData.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Fail</th>\n",
       "      <th>Predicted No Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Fail</th>\n",
       "      <td>565000</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual No Fail</th>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Fail  Predicted No Fail\n",
       "Actual Fail             565000             600000\n",
       "Actual No Fail          600000                  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnCostData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
